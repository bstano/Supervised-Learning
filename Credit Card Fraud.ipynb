{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Credit Card Fraud\n",
    "\n",
    "I want to make a model that can predcit if a credit card purchase is fraudulent. \n",
    "\n",
    "I will use anonymized credit card purchase data to make model the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud = pd.read_csv('C:\\Code\\Data\\creditcard.csv')\n",
    "display(fraud.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fraud.Class.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features have gone nameless to predict the identity protection measures this company takes. As such, it will be difficult to perform additional feature analysis. Instead, I will try many different models until I find the one best suited for the data.\n",
    "\n",
    "I can also see that the classes are extremely inbalanced. There are more than 280,000 reputable cases and only 492 fradulent ones.\n",
    "\n",
    "### Resampling Classes\n",
    "\n",
    "I will resample my data so that the classes are balanced. I will upsample fraud and downsample real purchases until their are 1000 of each, 2000 data points in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1000\n",
       "0    1000\n",
       "Name: Class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "real = fraud[fraud.Class==0]\n",
    "fake = fraud[fraud.Class==1]\n",
    " \n",
    "# Downsample real purchases class\n",
    "real_downsampled = resample(real, replace=True, n_samples=1000)\n",
    "#Upsample fake purchases class\n",
    "fake_upsampled = resample(fake, replace=True, n_samples=1000)\n",
    "\n",
    "sampled_fraud = pd.concat([real_downsampled, fake_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "display(sampled_fraud.Class.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Models\n",
    "\n",
    "Now that the classes are balanced I can begin running my various models. It should be noted that with this data fraudulent purchases are the positive class and reputable purchases are the negative. As such, false negatives, or Type II errors, are much worse and than false positives, or Type I errors. \n",
    "\n",
    "If a false positive happens, the customer will be called and alerted of fraud where none took place, so the customer will simply clear things up. However, if a false negative happens, fraud took place but wasn't detected at all. So it can continue to go on, damaging both the customer and the company.\n",
    "\n",
    "So, I will be sure to make a model thats overall accurate, but more importantly one that avoids type II errors.\n",
    "\n",
    "I will also perform a cross validation score using 3 folds to get a guage on how overfit each the models may get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data and outcome values to fit models with\n",
    "Xs = sampled_fraud.drop(['Class'], 1)\n",
    "Ys = sampled_fraud.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "The first model type I will use is Naive Bayes. It has the benefit of being very simple and inherently avoids Type II errors. But, as it doesn't learn at all, it can be hard to get it to be very accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Error Score:\n",
      "0.9085\n",
      "\n",
      "Type II Error Percentage:\n",
      "17.7 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[994   6]\n",
      " [177 823]]\n",
      "\n",
      "Cross Validation Score:\n",
      "0.91% +/- 0.02%\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(Xs, Ys)\n",
    "\n",
    "Y_predbnb = bnb.predict(Xs)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Ys, Y_predbnb).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('Naive Bayes Error Score:')\n",
    "print(bnb.score(Xs,Ys))\n",
    "print('\\nType II Error Percentage:')\n",
    "print(round(type2*100,2),\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Ys, Y_predbnb))\n",
    "cvscore = cross_val_score(bnb, Xs, Ys)\n",
    "print('\\nCross Validation Score:')\n",
    "print('{}% +/- {}%'.format(round(cvscore.mean(),2),round(cvscore.std()*2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is inaccurately, but not overly so. Still it is unuseabl it is current state and impossible to tune without knowing more about the data. I will discard my Naive Bayes model from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Logistic Regression\n",
    "\n",
    "Logistics Regression uses the natural log to make categorical outcomes to function like continous one, allowing for an ordinary least square regression like function to be performed. Additionally, I will use a Lasso error function, which will shrink useless terms down to zero, handy since I don't know anything about the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model was fit using C =  900\n"
     ]
    }
   ],
   "source": [
    "#find the best value of C to use when fitting the model\n",
    "grid = [.01,.1, 1,10,100,200,300,400,500,600,700,900,1000,5000,10000] \n",
    "out = [] \n",
    "for c in grid: \n",
    "    lrl = linear_model.LogisticRegression(penalty='l1',C=c) \n",
    "    lrl.fit(Xs, Ys) \n",
    "    scores = cross_val_score(lrl, Xs, Ys, cv=3) \n",
    "    out.append(scores.mean()) \n",
    "    bestc = grid[out.index(max(out))] \n",
    "\n",
    "lrl = linear_model.LogisticRegression(penalty='l1',C=bestc) \n",
    "lrl.fit(Xs,Ys)\n",
    "print(\"\\nThe model was fit using C = \",bestc)\n",
    "\n",
    "Y_predlrl = lrl.predict(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Logistic Regression Error Score:\n",
      "0.9595\n",
      "\n",
      "Type II Error Percentage:\n",
      "6.1 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[980  20]\n",
      " [ 61 939]]\n",
      "\n",
      "Cross Validation Score:\n",
      "0.95% +/- 0.01%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Ys, Y_predlrl).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('Lasso Logistic Regression Error Score:')\n",
    "print(lrl.score(Xs,Ys))\n",
    "print('\\nType II Error Percentage:')\n",
    "print(round(type2*100,2),\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Ys, Y_predlrl))\n",
    "cvscore = cross_val_score(lrl, Xs, Ys)\n",
    "print('\\nCross Validation Score:')\n",
    "print('{}% +/- {}%'.format(round(cvscore.mean(),2),round(cvscore.std()*2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is on the edge of useability, but not quite there. While the general model error score is barely past the acceptable 95%, it's type II error percentage is not so low. It is just over the line of unacceptability, at 6.1%. Since type II errors are much more impactful for this data set, I will discard the Lasso Logistic model as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Random Forests function as a group of simultaneous decision trees, all modeling a slightly different portion of the same data. They are extremely robust and do most feature engineering for you, with the tradeoff of being very prone to ovefitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "rfc.fit(Xs,Ys)\n",
    "\n",
    "Y_predrfc = rfc.predict(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Error Score:\n",
      "0.999\n",
      "\n",
      "Type II Error Percentage:\n",
      "0.2 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1000    0]\n",
      " [   2  998]]\n",
      "\n",
      "Cross Validation Score:\n",
      "0.98% +/- 0.0%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Ys, Y_predrfc).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('Random Forest Error Score:')\n",
    "print(rfc.score(Xs,Ys))\n",
    "print('\\nType II Error Percentage:')\n",
    "print(type2*100,\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Ys, Y_predrfc))\n",
    "cvscore = cross_val_score(rfc, Xs, Ys)\n",
    "print('\\nCross Validation Score:')\n",
    "print('{}% +/- {}%'.format(round(cvscore.mean(),2),round(cvscore.std()*2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error score and type II error percentage are superb. Not to mention, the cross validatio nscore shows the model has managed to prevent overfitting.  This model is definitely useable and I will try it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classification\n",
    "\n",
    "SVC works by making a boundary between the groups of data in n-dimensional space, where n is equal to the number of features. Here, the groups will simply be my binary outcomes. SVC is very powerful and accurate, but comes at the cost of being computationally intensive and prone to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC() # SVC defaults: kernel=rbf, degree of the poly is 3 svm_cv =cross_val_score(svm, train_data_bow, y_train, cv=10)\n",
    "svm.fit(Xs,Ys)\n",
    "\n",
    "Y_predsvm = svm.predict(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Error Score:\n",
      "1.0\n",
      "\n",
      "Type II Error Percentage:\n",
      "0.0 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1000    0]\n",
      " [   0 1000]]\n",
      "\n",
      "Cross Validation Score:\n",
      "0.88% +/- 0.01%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Ys, Y_predsvm).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('Support Vector Classifier Error Score:')\n",
    "print(svm.score(Xs,Ys))\n",
    "print('\\nType II Error Percentage:')\n",
    "print(type2*100,\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Ys, Y_predsvm))\n",
    "cvscore = cross_val_score(svm, Xs, Ys)\n",
    "print('\\nCross Validation Score:')\n",
    "print('{}% +/- {}%'.format(round(cvscore.mean(),2),round(cvscore.std()*2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM has an astonding 100% error score, meaning it has perfectly modeled the data. Unfortuneately, I can see from the cross validation score that there is probably some overfitting going on. Still, I will use the SVC model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Each Model on Original Data\n",
    "\n",
    "Now that I have determined which models were successful, Random Forest and SVC, and which were not, Naive Bayes and Lasso Logistic, I can test my models on the original, unsampled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data and outcome for model testing\n",
    "X = fraud.drop(['Class'], 1)\n",
    "Y = fraud.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Logistic Regression\n",
    "\n",
    "Even though I said before that the Lasso Logistic model did not work well enough to consider, I will test it anyway. I will do this because it was one the cusp of useability and simply as a thought experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Logistic Regression Error Score:\n",
      "0.9742281615269288\n",
      "\n",
      "Type II Error Percentage:\n",
      "7.52 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[277012   7303]\n",
      " [    37    455]]\n",
      "\n",
      "Cross Validation Score:\n",
      "1.0% +/- 0.0%\n"
     ]
    }
   ],
   "source": [
    "y_predlrl = lrl.predict(X)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y, Y_predlrl).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('Lasso Logistic Regression Error Score:')\n",
    "print(lrl.score(X,Y))\n",
    "print('\\nType II Error Percentage:')\n",
    "print(round(type2*100,2),\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Y, y_predlrl))\n",
    "cvscore = cross_val_score(lrl, X, Y)\n",
    "print('\\nCross Validation Score:')\n",
    "print('{}% +/- {}%'.format(round(cvscore.mean(),2),round(cvscore.std()*2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the error score for the model as a whole went up, the type II error suffered even more when reverting back to the original data. With Type II errors being even more important in the orginal data, with the imbalanced classes, I can say the model is performing worse overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "\n",
    "Now to try a functional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Error Score:\n",
      "0.9908007879019828\n",
      "\n",
      "Type II Error Percentage:\n",
      "2.03 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[281705   2610]\n",
      " [    10    482]]\n",
      "\n",
      "Cross Validation Score:\n",
      "0.67% +/- 0.93%\n"
     ]
    }
   ],
   "source": [
    "y_predrfc = rfc.predict(X)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y, Y_predrfc).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('Random Forest Error Score:')\n",
    "print(rfc.score(X,Y))\n",
    "print('\\nType II Error Percentage:')\n",
    "print(round(type2*100,2),\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Y, y_predrfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation Score has become very computationally intensive\n",
    "#cvscore = cross_val_score(rfc, X, Y)\n",
    "#print('\\nCross Validation Score:')\n",
    "#print('{}% +/- {}%'.format(round(cvscore.mean(),2),round(cvscore.std()*2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs almost as well in the test as it does in the model. If I run the cross valiadation score (which I won't since I has become very computationally intensive) I will see that the model works well acorss the different folds of data too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Test Error Score:\n",
      "0.9997296414765087\n",
      "\n",
      "Type II Error Percentage:\n",
      "11.59 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[284295     20]\n",
      " [    57    435]]\n"
     ]
    }
   ],
   "source": [
    "y_psvm = svm.predict(X)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y, y_psvm).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('Support Vector Classifier Test Error Score:')\n",
    "print(svm.score(X,Y))\n",
    "print('\\nType II Error Percentage:')\n",
    "print(round(type2*100,2),\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Y, y_psvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation Score has become very computationally intensive\n",
    "#cvscore = cross_val_score(svm, Xs, Ys)\n",
    "#print('\\nCross Validation Score:')\n",
    "#print('{}% +/- {}%'.format(round(cvscore.mean(),2),round(cvscore.std()*2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classification works much worse in testing than it did in training.  It seems the slight overfitness I observed has a larger impact than previously thought. The support vector machine has an even higher type II error percentage than the lasso logistic model, despite heavily outperforming it in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Despite the Support Vector Classification model seeming the best during training, the Random Forest Classification model heavily outperformed it during testing. The SVC model's good error scores during traing were only possible because of how overfit the model truly was. This shows just how important training and testing on different data sets is and well as just how important is it to know your data and recognize what type of error hurts it the most. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
