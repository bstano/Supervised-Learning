{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Credit Card Fraud\n",
    "\n",
    "I want to make a model that can predcit if a credit card purchase is fraudulent. \n",
    "\n",
    "I will use anonymized credit card purchase data to make model the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud = pd.read_csv('C:\\Code\\Data\\creditcard.csv')\n",
    "print(fraud.shape)\n",
    "display(fraud.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fraud.Class.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features have gone nameless to predict the identity protection measures this company takes. As such, it will be difficult to perform additional feature analysis. Instead, I will try many different models until I find the one best suited for the data.\n",
    "\n",
    "I can also see that the classes are extremely inbalanced. There are more than 280,000 reputable cases and only 492 fradulent ones.\n",
    "\n",
    "### Resampling Classes and Creating Test Data\n",
    "\n",
    "I will resample my data so that the classes are balanced. I will upsample fraud and downsample real purchases until their are 1000 of each, 2000 data points in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1000\n",
       "0    1000\n",
       "Name: Class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "real = fraud[fraud.Class==0]\n",
    "fake = fraud[fraud.Class==1]\n",
    " \n",
    "# Downsample real purchases class\n",
    "real_downsampled = resample(real, replace=True, n_samples=1000)\n",
    "#Upsample fake purchases class\n",
    "fake_upsampled = resample(fake, replace=True, n_samples=1000)\n",
    "\n",
    "sampled_fraud = pd.concat([real_downsampled, fake_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "display(sampled_fraud.Class.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data and outcome values for training, or smapled, set\n",
    "Xs = sampled_fraud.drop(['Class'], 1)\n",
    "Ys = sampled_fraud.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data and outcome for test model\n",
    "Xt = fraud.drop(['Class'], 1)\n",
    "Yt = fraud.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Models\n",
    "\n",
    "Now that the classes are balanced I can begin running my various models. It should be noted that with this data fraudulent purchases are the positive class and reputable purchases are the negative. As such, false negatives, or Type II errors, are much worse and than false positives, or Type I errors. \n",
    "\n",
    "If a false positive happens, the customer will be called and alerted of fraud where none took place, so the customer will simply clear things up. However, if a false negative happens, fraud took place but wasn't detected at all. So it can continue to go on, damaging both the customer and the company.\n",
    "\n",
    "So, I will be sure to make a model thats overall accurate, but more importantly one that avoids type II errors.\n",
    "\n",
    "I will also perform a cross validation score using 3 folds to get a guage on how overfit each the models may get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "The first model type I will use is Naive Bayes. It has the benefit of being very simple and inherently avoids Type II errors. But, as it doesn't learn at all, it can be hard to get it to be very accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to hold the testing scores in \n",
    "scores = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training Set:\n",
      "\n",
      "Accuracy Score:\n",
      "0.901\n",
      "\n",
      "Cross Validation Score:\n",
      "0.9% +/- 0.02%\n",
      "\n",
      "Naive Bayes Testing Set:\n",
      "\n",
      "Testing Accuracy Score:\n",
      "0.9905374516778028\n",
      "\n",
      "Cross Validation Score:\n",
      "1.0% +/- 0.0%\n",
      "\n",
      "Type II Error Percentage:\n",
      "17.48 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[281706   2609]\n",
      " [    86    406]]\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(Xs, Ys)\n",
    "\n",
    "Y_predbnb = bnb.predict(Xt)\n",
    "\n",
    "cvscores = cross_val_score(bnb, Xs, Ys)\n",
    "cvscoret = cross_val_score(bnb, Xt, Yt)\n",
    "print(\"Naive Bayes Training Set:\")\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(bnb.score(Xs,Ys))\n",
    "print('\\nCross Validation Score:')\n",
    "print('{}% +/- {}%'.format(round(cvscores.mean(),2),round(cvscores.std()*2,2)))\n",
    "print(\"\\nNaive Bayes Testing Set:\")\n",
    "print('\\nTesting Accuracy Score:')\n",
    "print(bnb.score(Xt,Yt))\n",
    "print('\\nCross Validation Score:')\n",
    "print('{}% +/- {}%'.format(round(cvscoret.mean(),2),round(cvscoret.std()*2,2)))\n",
    "tn, fp, fn, tp = confusion_matrix(Yt, Y_predbnb).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('\\nType II Error Percentage:')\n",
    "print(round(type2*100,2),\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Yt, Y_predbnb))\n",
    "\n",
    "scores['Naive Bayes'] = [bnb.score(Xt,Yt),type2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is inaccurately, but not overly so. Still it is unuseabl it is current state and impossible to tune without knowing more about the data. I will discard my Naive Bayes model from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Logistic Regression\n",
    "\n",
    "Logistics Regression uses the natural log to make categorical outcomes to function like continous one, allowing for an ordinary least square regression like function to be performed. Additionally, I will use a Lasso error function, which will shrink useless terms down to zero, handy since I don't know anything about the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model was fit using C =  400\n"
     ]
    }
   ],
   "source": [
    "#find the best value of C to use when fitting the model\n",
    "grid = [.01,.1, 1,10,100,200,300,400,500,600,700,900,1000,5000,10000] \n",
    "out = [] \n",
    "for c in grid: \n",
    "    lrl = linear_model.LogisticRegression(penalty='l1',C=c) \n",
    "    lrl.fit(Xs, Ys) \n",
    "    score = cross_val_score(lrl, Xs, Ys, cv=3) \n",
    "    out.append(score.mean()) \n",
    "    bestc = grid[out.index(max(out))] \n",
    "\n",
    "lrl = linear_model.LogisticRegression(penalty='l1',C=bestc) \n",
    "lrl.fit(Xs,Ys)\n",
    "print(\"\\nThe model was fit using C = \",bestc)\n",
    "\n",
    "Y_predlrl = lrl.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Logistic Training Set:\n",
      "\n",
      "Traing Accuracy Score:\n",
      "0.946\n",
      "\n",
      "Cross Validation Score:\n",
      "0.94% +/- 0.01%\n",
      "\n",
      "Lasso Logistic Testing Set:\n",
      "\n",
      "Testing Accuracy Score:\n",
      "0.9693476635054616\n",
      "\n",
      "Cross Validation Score:\n",
      "1.0% +/- 0.0%\n",
      "\n",
      "Type II Error Percentage:\n",
      "7.72 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[275623   8692]\n",
      " [    38    454]]\n"
     ]
    }
   ],
   "source": [
    "cvscores = cross_val_score(lrl, Xs, Ys)\n",
    "cvscoret = cross_val_score(lrl, Xt, Yt)\n",
    "print(\"Lasso Logistic Training Set:\")\n",
    "print(\"\\nTraing Accuracy Score:\")\n",
    "print(lrl.score(Xs,Ys))\n",
    "print('\\nCross Validation Score:')\n",
    "print('{}% +/- {}%'.format(round(cvscores.mean(),2),round(cvscores.std()*2,2)))\n",
    "print(\"\\nLasso Logistic Testing Set:\")\n",
    "print('\\nTesting Accuracy Score:')\n",
    "print(lrl.score(Xt,Yt))\n",
    "print('\\nCross Validation Score:')\n",
    "print('{}% +/- {}%'.format(round(cvscoret.mean(),2),round(cvscoret.std()*2,2)))\n",
    "tn, fp, fn, tp = confusion_matrix(Yt, Y_predlrl).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('\\nType II Error Percentage:')\n",
    "print(round(type2*100,2),\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Yt, Y_predlrl))\n",
    "\n",
    "scores['Lasso Logistic'] = [lrl.score(Xt,Yt),type2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is on the edge of useability, but not quite there. While the general model error score is barely past the acceptable 95%, it's type II error percentage is not so low. It is just over the line of unacceptability, at 6.1%. Since type II errors are much more impactful for this data set, I will discard the Lasso Logistic model as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Random Forests function as a group of simultaneous decision trees, all modeling a slightly different portion of the same data. They are extremely robust and do most feature engineering for you, with the tradeoff of being very prone to ovefitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "rfc.fit(Xs,Ys)\n",
    "\n",
    "Y_predrfc = rfc.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Set:\n",
      "\n",
      "Traing Accuracy Score:\n",
      "0.9995\n",
      "\n",
      "Random Forest Testing Set:\n",
      "\n",
      "Testing Accuracy Score:\n",
      "0.9903689164943278\n",
      "\n",
      "Type II Error Percentage:\n",
      "2.44 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[281584   2731]\n",
      " [    12    480]]\n"
     ]
    }
   ],
   "source": [
    "#cvscores = cross_val_score(rfc, Xs, Ys)\n",
    "#cvscoret = cross_val_score(rfc, Xt, Yt)\n",
    "print(\"Random Forest Training Set:\")\n",
    "print(\"\\nTraing Accuracy Score:\")\n",
    "print(rfc.score(Xs,Ys))\n",
    "#print('\\nCross Validation Score:')\n",
    "#print('{}% +/- {}%'.format(round(cvscores.mean(),2),round(cvscores.std()*2,2)))\n",
    "print(\"\\nRandom Forest Testing Set:\")\n",
    "print('\\nTesting Accuracy Score:')\n",
    "print(rfc.score(Xt,Yt))\n",
    "#print('\\nCross Validation Score:')\n",
    "#print('{}% +/- {}%'.format(round(cvscoret.mean(),2),round(cvscoret.std()*2,2)))\n",
    "tn, fp, fn, tp = confusion_matrix(Yt, Y_predrfc).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('\\nType II Error Percentage:')\n",
    "print(round(type2*100,2),\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Yt, Y_predrfc))\n",
    "\n",
    "scores['Random Forest'] = [rfc.score(Xt,Yt),type2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error score and type II error percentage are superb. Not to mention, the cross validatio nscore shows the model has managed to prevent overfitting.  This model is definitely useable and I will try it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classification\n",
    "\n",
    "SVC works by making a boundary between the groups of data in n-dimensional space, where n is equal to the number of features. Here, the groups will simply be my binary outcomes. SVC is very powerful and accurate, but comes at the cost of being computationally intensive and prone to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC() # SVC defaults: kernel=rbf, degree of the poly is 3 svm_cv =cross_val_score(svm, train_data_bow, y_train, cv=10)\n",
    "svm.fit(Xs,Ys)\n",
    "\n",
    "Y_predsvm = svm.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classification Training Set:\n",
      "\n",
      "Traing Accuracy Score:\n",
      "1.0\n",
      "\n",
      "Support Vector Classification Testing Set:\n",
      "\n",
      "Testing Accuracy Score:\n",
      "0.9996559073337383\n",
      "\n",
      "Type II Error Percentage:\n",
      "15.65 %\n",
      "\n",
      "Confusion Matrix:\n",
      "[[284294     21]\n",
      " [    77    415]]\n"
     ]
    }
   ],
   "source": [
    "#cvscores = cross_val_score(svm, Xs, Ys)\n",
    "#cvscoret = cross_val_score(svm, Xt, Yt)\n",
    "print(\"Support Vector Classification Training Set:\")\n",
    "print(\"\\nTraing Accuracy Score:\")\n",
    "print(svm.score(Xs,Ys))\n",
    "#print('\\nCross Validation Score:')\n",
    "#print('{}% +/- {}%'.format(round(cvscores.mean(),2),round(cvscores.std()*2,2)))\n",
    "print(\"\\nSupport Vector Classification Testing Set:\")\n",
    "print('\\nTesting Accuracy Score:')\n",
    "print(svm.score(Xt,Yt))\n",
    "#print('\\nCross Validation Score:')\n",
    "#print('{}% +/- {}%'.format(round(cvscoret.mean(),2),round(cvscoret.std()*2,2)))\n",
    "tn, fp, fn, tp = confusion_matrix(Yt, Y_predsvm).ravel()\n",
    "type2 = fn/(fn+tp)\n",
    "print('\\nType II Error Percentage:')\n",
    "print(round(type2*100,2),\"%\")\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(Yt, Y_predsvm))\n",
    "\n",
    "scores['Support Vector Machines'] = [svm.score(Xt,Yt),type2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Now that I have attempted to predict credit card fraud with all the model types, I can say what type of model worked best.\n",
    "\n",
    "A quick recap of each model type's ability to predict fraud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Lasso Logistic</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Support Vector Machines</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <td>0.990537</td>\n",
       "      <td>0.969348</td>\n",
       "      <td>0.990369</td>\n",
       "      <td>0.999656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type II Error</th>\n",
       "      <td>0.174797</td>\n",
       "      <td>0.077236</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.156504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Naive Bayes  Lasso Logistic  Random Forest  \\\n",
       "Stat                                                           \n",
       "Testing Accuracy     0.990537        0.969348       0.990369   \n",
       "Type II Error        0.174797        0.077236       0.024390   \n",
       "\n",
       "                  Support Vector Machines  \n",
       "Stat                                       \n",
       "Testing Accuracy                 0.999656  \n",
       "Type II Error                    0.156504  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores['Stat'] = ['Testing Accuracy','Type II Error']\n",
    "scores = scores.set_index('Stat')\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the Support Vector Classification model seeming the best during training, the Random Forest Classification model heavily outperformed it during testing. The SVC model's good error scores during traing were only possible because of how overfit the model truly was. This shows just how important training and testing on different data sets is and well as just how important is it to know your data and recognize what type of error hurts it the most. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
